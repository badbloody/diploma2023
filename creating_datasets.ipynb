{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMh9nlUNc6lj7IY1QWzLl2z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badbloody/diploma2023/blob/main/creating_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the needed libraries"
      ],
      "metadata": {
        "id": "Ttizvclow9np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "aJ51dOYoxBuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to Google Drive so we can safely store our downloaded images without them disappearing after the Colab session is over"
      ],
      "metadata": {
        "id": "fQ1OtGFQ4VTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA9vEqte4UYd",
        "outputId": "416c0d7d-335a-46a7-837f-70f0cbba07ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining parameters"
      ],
      "metadata": {
        "id": "KAYeJ1YFqpup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" PARAMETERS \"\"\"\n",
        "number_of_images = 10000 # how many images from the COCO dataset, which will be used as content images, you want to download\n",
        "dataset_dir = \"/content/gdrive/MyDrive/content_dataset\" # where you want to save the content images\n",
        "train_ratio_content = 0.99 # the ratio of content images you want to use for training\n",
        "train_ratio_style = 0.8 # the ratio of style images you want to use for training"
      ],
      "metadata": {
        "id": "XJM34rAJrLZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" DON'T CHANGE THESE \"\"\"\n",
        "\n",
        "cnn_normalization_mean = [0.485, 0.456, 0.406]\n",
        "cnn_normalization_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=cnn_normalization_mean, std=cnn_normalization_std)\n",
        "])\n"
      ],
      "metadata": {
        "id": "X2sc82MV2pUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "dEydUOCcuiVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function that will download the desired number of content images from the COCO dataset and store them in the provided folder:"
      ],
      "metadata": {
        "id": "Mw7leMVCxcz2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dEb2uAAqRQd"
      },
      "outputs": [],
      "source": [
        "def download_and_extract_coco(dataset_dir, number_of_images):\n",
        "    # download annotations\n",
        "    annotations_url = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
        "    annotations_path = dataset_dir + \"/annotations.zip\"\n",
        "\n",
        "    # create the directory passed as the first argument\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "    # download annotations zip file\n",
        "    print(\"Downloading annotations...\")\n",
        "    response = requests.get(annotations_url, stream=True)\n",
        "    with open(annotations_path, \"wb\") as file:\n",
        "        shutil.copyfileobj(response.raw, file)\n",
        "\n",
        "    # extract the annotations\n",
        "    print(\"Extracting annotations...\")\n",
        "    with zipfile.ZipFile(annotations_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(dataset_dir)\n",
        "\n",
        "    # download images\n",
        "    images_url = \"http://images.cocodataset.org/zips/train2017.zip\"\n",
        "    images_path = dataset_dir + \"/images.zip\"\n",
        "\n",
        "    # Download images zip file\n",
        "    print(\"Downloading images...\")\n",
        "    response = requests.get(images_url, stream=True)\n",
        "    with open(images_path, \"wb\") as file:\n",
        "        shutil.copyfileobj(response.raw, file)\n",
        "\n",
        "    # extracting images\n",
        "    print(\"Extracting images...\")\n",
        "    with zipfile.ZipFile(images_path, \"r\") as zip_ref:\n",
        "        selected_images = zip_ref.infolist()[:number_of_images]\n",
        "        zip_ref.extractall(dataset_dir, members=selected_images)\n",
        "\n",
        "    # removing the files afterwards\n",
        "    os.remove(annotations_path)\n",
        "    os.remove(images_path)\n",
        "\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A helper function that splits the dataset into training and validation subsets\n"
      ],
      "metadata": {
        "id": "YH7Ok_uRxo-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.utils.path import target_update\n",
        "def split_dataset(dataset_dir, train_ratio):\n",
        "    # create directories for train and validation sets\n",
        "    if \"/train2017\" in dataset_dir:\n",
        "      train_dir = dataset_dir.replace(\"/train2017\", \"_train\")\n",
        "      val_dir = dataset_dir.replace(\"/train2017\", \"_val\")\n",
        "    else:\n",
        "      train_dir = dataset_dir + \"_train\"\n",
        "      val_dir = dataset_dir + \"_val\"\n",
        "\n",
        "    if not os.path.exists(train_dir):\n",
        "      os.makedirs(train_dir, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(val_dir):\n",
        "      os.makedirs(val_dir, exist_ok=target_update)\n",
        "\n",
        "    # get the list of files in the dataset directory\n",
        "    files = os.listdir(dataset_dir)\n",
        "    random.shuffle(files)\n",
        "\n",
        "    # calculate the number of files for training and validation\n",
        "    total_files = len(files)\n",
        "    train_count = int(train_ratio * total_files)\n",
        "    val_count = total_files - train_count\n",
        "\n",
        "    # move files to the created train and validation directories\n",
        "    for i, file in enumerate(files):\n",
        "        src_path = os.path.join(dataset_dir, file)\n",
        "        if i < train_count:\n",
        "            dst_path = os.path.join(train_dir, file)\n",
        "        else:\n",
        "            dst_path = os.path.join(val_dir, file)\n",
        "        shutil.move(src_path, dst_path) #move from source to destination path\n",
        "\n",
        "    print(\"Dataset has been split into train and validation sets!\")"
      ],
      "metadata": {
        "id": "k-AnbeWhw2yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to create a train folder inside our content folder - this is due to the library torchvision.datasets.Imagefolder needing there to be some classes within a folder in order to create a dataset"
      ],
      "metadata": {
        "id": "3PjKKXCUJgzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def move_files_within_folder(source_folder, destination_folder):\n",
        "    # get the absolute paths for the source and destination folders\n",
        "    source_folder_abs = os.path.abspath(source_folder)\n",
        "    destination_folder_abs = os.path.join(source_folder_abs, destination_folder)\n",
        "\n",
        "    # create the destination folder if it doesn't exist\n",
        "    if not os.path.exists(destination_folder_abs):\n",
        "        os.makedirs(destination_folder_abs)\n",
        "\n",
        "    # get the list of files in the source folder\n",
        "    files = os.listdir(source_folder_abs)\n",
        "\n",
        "    for file_name in files:\n",
        "        # get the absolute path of the current file\n",
        "        file_abs_path = os.path.join(source_folder_abs, file_name)\n",
        "\n",
        "        # check if the current item is a file (not a directory)\n",
        "        if os.path.isfile(file_abs_path):\n",
        "            # Move the file to the destination folder\n",
        "            shutil.move(file_abs_path, os.path.join(destination_folder_abs, file_name))"
      ],
      "metadata": {
        "id": "HN7bFF6NGvFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the content dataset"
      ],
      "metadata": {
        "id": "j3ylqS-90ckt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_and_extract_coco(dataset_dir, number_of_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_DRyKiA8V9E",
        "outputId": "451b63d2-f306-4898-f47b-a8bc374c8a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annotations...\n",
            "Extracting annotations...\n",
            "Downloading images...\n",
            "Extracting images...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset(dataset_dir+\"/train2017\", train_ratio_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiXE7-gltnmz",
        "outputId": "020ce76a-e5f6-4e66-c072-9d035fc317ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has been split into train and validation sets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_folder = dataset_dir + \"_train\"\n",
        "destination_folder = dataset_dir + \"_train/train\"\n",
        "\n",
        "move_files_within_folder(source_folder, destination_folder)"
      ],
      "metadata": {
        "id": "gWjs27EPInMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(destination_folder)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSu9BVtonWLz",
        "outputId": "137a4819-4751-4963-add7-43086a4a4b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content_dataset = torchvision.datasets.ImageFolder(root= dataset_dir + \"_train\", transform= data_transform)"
      ],
      "metadata": {
        "id": "azk6QjVQyYo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the style dataset"
      ],
      "metadata": {
        "id": "7JWsTbdz2cGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we clone the repository from GitHub:"
      ],
      "metadata": {
        "id": "L2qBz789rvvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/badbloody/diplomskiSlike"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGgO8YgN2bn2",
        "outputId": "993f2d54-3acd-4734-932b-4d051e0047fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'diplomskiSlike' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the paths of our folders - the `source_folder` being the one which we cloned from GitHub; the `train_folder` and `val_folder`are the paths where we will store the datasets after the split - they don't have to exist, the function `split_style_dataset` will create them."
      ],
      "metadata": {
        "id": "yHljhSC_s2ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_folder = '/content/diplomskiSlike'\n",
        "train_folder = '/content/style_train'\n",
        "val_folder = '/content/style_val'"
      ],
      "metadata": {
        "id": "AnjLAVxCtNCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function that will split our style images into train and val; it is different from the function we used for the splitting the content images due to having multiple classes in our style dataset."
      ],
      "metadata": {
        "id": "F-Lnhldlt_aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_style_dataset(source_folder, train_folder, val_folder, validation_split=0.2, random_seed=None):\n",
        "    if not os.path.exists(source_folder):\n",
        "        print(\"Source folder does not exist.\")\n",
        "        return\n",
        "\n",
        "    if not os.path.exists(train_folder):\n",
        "        os.makedirs(train_folder)\n",
        "\n",
        "    if not os.path.exists(val_folder):\n",
        "        os.makedirs(val_folder)\n",
        "\n",
        "    class_folders = [folder for folder in os.listdir(source_folder) if os.path.isdir(os.path.join(source_folder, folder))]\n",
        "\n",
        "    if random_seed is not None:\n",
        "        random.seed(random_seed)\n",
        "\n",
        "    for class_folder in class_folders:\n",
        "        class_source_path = os.path.join(source_folder, class_folder)\n",
        "        class_train_path = os.path.join(train_folder, class_folder)\n",
        "        class_val_path = os.path.join(val_folder, class_folder)\n",
        "\n",
        "        if not os.path.exists(class_train_path):\n",
        "            os.makedirs(class_train_path)\n",
        "\n",
        "        if not os.path.exists(class_val_path):\n",
        "            os.makedirs(class_val_path)\n",
        "\n",
        "        images = [img for img in os.listdir(class_source_path) if img.endswith('.jpg') or img.endswith('.png')]\n",
        "\n",
        "        num_val_samples = int(len(images) * validation_split)\n",
        "        val_samples = random.sample(images, num_val_samples)\n",
        "        train_samples = [img for img in images if img not in val_samples]\n",
        "\n",
        "        for img in val_samples:\n",
        "            src_path = os.path.join(class_source_path, img)\n",
        "            dest_path = os.path.join(class_val_path, img)\n",
        "            shutil.copy(src_path, dest_path)\n",
        "\n",
        "        for img in train_samples:\n",
        "            src_path = os.path.join(class_source_path, img)\n",
        "            dest_path = os.path.join(class_train_path, img)\n",
        "            shutil.copy(src_path, dest_path)\n",
        "\n",
        "    print(\"Split completed!\")"
      ],
      "metadata": {
        "id": "S-UH3Z85m2q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_style_dataset(source_folder, train_folder, val_folder, validation_split=1-train_ratio_style, random_seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyGK6j_Knt2c",
        "outputId": "7b419259-2768-4b2d-db1c-9dfb66fd7563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an error when calling `torchvision.datasets.ImageFolder` due to there being some .git files in our folders, so here is a helper function to get rid of them"
      ],
      "metadata": {
        "id": "OjpwGYmCqau7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_git_folders(directory):\n",
        "    for root, dirs, _ in os.walk(directory):\n",
        "        if '.git' in dirs:\n",
        "            git_folder_path = os.path.join(root, '.git')\n",
        "            shutil.rmtree(git_folder_path)\n",
        "            print(f\"Removed .git folder at: {git_folder_path}\")\n",
        "            dirs.remove('.git')\n",
        "\n",
        "directory_to_clean = '/content/style_train'\n",
        "remove_git_folders(directory_to_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4XCYLpwpcLO",
        "outputId": "0ceffd9e-a704-4ff6-b64d-070dbf695dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed .git folder at: /content/style_train/.git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "style_dataset = torchvision.datasets.ImageFolder(train_folder, transform= data_transform)"
      ],
      "metadata": {
        "id": "VzToTlB6njkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the content and style datasets are ready for the training stage."
      ],
      "metadata": {
        "id": "BZSsFitrKW7z"
      }
    }
  ]
}